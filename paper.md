- [DAG](#dag)
  - [2022](#2022)
- [schedule&scale](#schedule&scale)
- [config](#config)

  
  
# DAG/工作流调度

## 2022

### Towards Efficient Processing of Latency-Sensitive Serverless DAGs at the Edge

**摘要：**
许多新兴的新应用程序期望“接近实时”的处理和响应，这是今天的云无法保证的，需要在边缘进行处理。对于边缘环境来说，无服务器计算是一种特别有前途的架构，因为它可以通过精确地扩展资源来满足应用程序的需求，从而提高效率。随着边缘应用程序变得越来越复杂，并由一组更简单的功能或微服务组成，需要支持更复杂的功能拓扑，这些拓扑可以表示为有向无环图(dag)。然而，在无服务器平台上运行DAG函数会带来与互连、实例化和调度功能沙箱相关的新挑战。在本文中，我们将探讨如何扩展Sledge(一个基于wasm的无服务器运行时)以支持DAG功能。Sledge独特的设计允许极其轻量级的沙盒实例化——每个函数调用可以在30微秒内启动一个新的沙盒——这减轻了冷启动问题，而冷启动问题对dag尤其有害。增强的Sledge框架不依赖于通过共享存储进行昂贵的协调，而是提供了一个**快速的内存通信通道**来通过DAG传播数据。我们考虑带有服务级别目标的dag，这些目标由它们的**执行期限定义**。为了确保dag满足它们的性能需求，我们在各种实际工作负载上考虑、分析和比较了两个截止日期感知的可插拔调度器(我们在Sledge中实现的)。

**数据传输问题**
为了满足用户需求，主要的无服务器提供商最近推出了对无服务器功能工作流组合的支持，如A WS Step Functions[3]、Azure Durable Functions[4]和Google Cloud Composer[10]。由于现有的无服务器平台是无状态的，因此DAG中功能之间的数据交换需要通过远程存储(例如S3)保存和加载这些数据，如图1所示。据文献[20]报道，通过远程存储传递数据会消耗75%以上的函数执行时间。因此，在功能之间交换中间数据是云无服务器工作流中的一个主要挑战。

## 2022

###  SoDa: A Serverless-Oriented Deadline-Aware Workflow Scheduling Engine for IoT Applications in Edge Clouds

**摘要：**
工作流作为一种协调工具，具有大量相互依赖任务的工作流日益成为大规模复杂物联网应用中协调计算密集型任务的新范式。无服务器计算最近也被应用于网络边缘的现实问题，主要针对基于事件的物联网应用。然而，现有的基于虚拟机资源模型的工作流调度算法在无服务器平台上无法保证用户的QoS (Quality of Service)。本文设计了一种基于无服务器架构的边缘云弹性工作流调度框架EWSF。此外，我们提出了一种面向无服务器的截止日期感知工作流调度算法，称为SoDa。此外，我们实现了基于Knative和Kubernetes的EWSF原型，并集成了SoDa作为调度引擎。SoDa的性能在实验平台上与六种同类产品进行了对比验证。实验结果表明，SoDa能够适应各种调度环境，在总完工时间和执行成功率方面都取得了较好的性能。在集群资源紧张的情况下，与第二优算法相比，SoDa将总完工时间和成功率分别提高了10.4%和55%。

**小结**
边缘云是建立在边缘上的云计算平台。服务工作流是边缘云环境下的重要难点之一。提出了一种基于云边缘的移动电子商务环境下服务工作流动态重构方案，该方案更适合于边缘云环境[14]。边缘云中的任务调度通常具有大量的任务。对于云系统中的任务调度，文献已经展示了广泛的研究主体，涵盖了广泛的任务调度方面，以优化成本、执行时间、能源、可靠性、安全性和能源等目标[15-17]。Topcuoglu等[18]提出了一种最好的启发式调度算法——异构最早完成时间(HEFT)算法，通过最小化关键任务的最早完成时间来最小化整个工作流的最大完成时间。HEFT算法存在优化和扩展版本。然而，该技术对于大规模工作流并不有效。

无服务器架构的概念最早是由Ken Form提出的[19]。2014年，AWS推出了FaaS平台AWS Lambda[20]。一些研究工作集中在无服务器平台上，评估或改进特定无服务器平台的性能。例如，Kuntsevich等[21]将计算密集型任务、内存密集型任务和web任务结合起来，在Apache OpenWhisk平台上执行性能测试，测量平台的CPU、内存、磁盘和延迟指标。Lin和Glikson[22]提出了一种优化方法来提高Knative平台的冷启动性能。

# schedule&scale

## 2021

### Atoll: A Scalable Low-Latency Serverless Platform

**摘要：**
随着面向用户的应用采用无服务器计算，无服务器平台良好的延迟性能已经成为一个强有力的基本要求。然而，由于其底层控制和数据平面的设计特别不适合具有不可预测到达模式的短期功能，因此在当今的平台上实现这一点是非常困难的。我们介绍了Atoll，一个无服务器平台，它通过对控制和数据平面的重新设计来克服这些挑战。在Atoll中，每个应用程序都与延迟截止日期相关联。Atoll通过以下方式实现其每个应用程序请求延迟目标:(a)将集群划分为(半全局调度器，工作池)对，(b)执行截止日期感知调度和主动沙盒分配，以及(c)使用负载平衡层进行沙盒感知路由，并自动扩展每个应用程序的半全局调度器。我们的结果表明，与最先进的替代方案相比，Atoll减少了错过的截止日期，减少了错失的截止日期，并减少了错失的尾延迟。

**小结**
该文发表在SOCC上，不仅设计了沙箱池来执行函数，还设计了考虑不同因素的scale策略，对沙箱进行管理。

**借鉴点**
此外，目前的无服务器计算平台[2-4]不考虑函数的执行时间，也不允许用户定义请求的优先级，不清楚它们是否对请求进行优先排序，以确保延迟在预期范围内。
[2] Microsoft. Azure Functions[EB/OL]. 2024. https://functions.azure.com.
Google. Google Cloud Functions[EB/OL]. 2024. https://cloud.google.com/functions. 
 Amazon. AWS Lambda[EB/OL]. 2024. https://aws.amazon.com/cn/lambda/.


# config

## 2020

### Sequoia: Enabling ￿ality-of-Service in Serverless Computing

**摘要：**
无服务器计算是一种快速发展的范例，它可以轻松地利用云的力量。使用无服务器计算，开发人员只需向云提供商提供事件驱动的功能，提供商就可以无缝地扩展功能调用，以满足事件触发器发生时的需求。由于当前和未来的无服务器产品支持各种各样的无服务器应用程序，因此管理无服务器工作负载的有效技术成为一个重要问题。这项工作检查了云提供商当前的管理和调度实践，揭示了许多问题，包括相关的应用程序运行时、功能下降、在线客户端分配以及其他未记录的和意外的行为。为了解决这些问题，设计了一个新的服务质量功能调度和分配框架，称为Sequoia。Sequoia允许开发人员或管理员轻松地了解应该如何部署无服务器功能和应用程序、设置上限、确定优先级，或者基于确定的、灵活的策略进行更改。控制和真实工作负载的结果显示，Sequoia无缝适应策略，消除链中掉落，将排队时间减少至多6.4、加强严格的链级公平性，并将运行时性能提高至多25倍。


**小结**
该论文总结了云提供商当前的管理和调度实践。

### Characterizing Serverless Platforms with ServerlessBench

**小结**
该论文总结了serverless的一些特性，值得反复揣摩。

服务器平台通常按分配的资源(例如内存和CPU资源)的比例收取执行费用，这通常由功能执行期间的峰值资源需求决定。因此，在执行期间的低资源需求阶段，资源被过度供应和过度收费。我们在AWS Lambda上评估了一个cpu密集型的Alu应用程序，并分析了它作为单个函数执行或分成两个函数执行时的执行账单。应用程序由两个执行阶段组成:在第一阶段，它连接到S3并请求一个数字N(加载配置阶段);在第二阶段，它生成100个线程来进行N次算术计算(计算阶段)。


## 2022

###  Help rather than recycle: Alleviating cold startup in serverless computing through inter-function container sharing

**摘要：**
在无服务器计算中，每个函数调用都在容器(或虚拟机)中执行，容器冷启动会导致较长的响应延迟。我们观察到一些函数的冷容器启动，而其他函数的热容器空闲。根据观察，除了从头为一个函数启动一个新容器之外，我们建议通过重新利用另一个函数的一个热的但空闲的容器来缓解冷启动。为了达到这个目的，我们实现了一个名为Pagurus的容器管理方案。Pagurus包括一个功能内部管理器，用于将空闲的热容器替换为其他功能可以使用的容器，而不会引入额外的安全问题;一个功能间调度器，用于在功能之间调度容器;以及一个集群级的共享感知功能平衡器，用于在不同节点之间平衡工作负载。使用Azure无服务器跟踪的实验表明，Pagurus缓解了84.6%的冷启动，并且冷启动延迟从数百毫秒减少到16毫秒。

## 2023

### AQUATOPE: QoS-and-Uncertainty-Aware Resource Management for Multi-stage Serverless Workflows

**摘要：**
多阶段无服务器应用程序，即具有许多计算和I/O阶段的工作流，正日益成为FaaS平台的代表。尽管这些应用程序在细粒度可伸缩性和模块化开发方面具有优势，但与以前的简单无服务器功能相比，这些应用程序存在性能欠佳、资源效率低下和高成本的问题。
我们提出了Aquatope，一个面向端到端无服务器工作流的qos和不确定性感知资源调度器，它考虑了FaaS平台中存在的固有不确定性，并提高了性能可预测性和资源效率。Aquatope使用一组可扩展且经过验证的贝叶斯模型，在函数调用之前创建预热的容器，并在函数粒度上分配适当的资源，以满足复杂工作流的端到端QoS，同时最大限度地降低资源成本。在各种分析和交互式多阶段无服务器工作负载中，Aquatope显著优于先前的系统，与其他QoS会议方法相比，将QoS违反减少了5倍，平均成本降低了34%，最高可达52%。
